# ğŸš€ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•å°† Python å¤šé¡¹ç›®å¹³å°éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒã€‚

## ğŸ“‹ ç”Ÿäº§ç¯å¢ƒè¦æ±‚

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04 LTS æˆ– CentOS 8+
- **CPU**: 4 æ ¸å¿ƒä»¥ä¸Š (æ¨è 8 æ ¸å¿ƒ)
- **å†…å­˜**: 16GB RAM ä»¥ä¸Š (æ¨è 32GB)
- **å­˜å‚¨**: 100GB SSD ä»¥ä¸Š (æ¨è NVMe SSD)
- **ç½‘ç»œ**: ç¨³å®šçš„ç½‘ç»œè¿æ¥ï¼Œæ¨èä¸“çº¿

### è½¯ä»¶è¦æ±‚

- **Python**: 3.9+ (æ¨è 3.11)
- **Docker**: 20.10+
- **Docker Compose**: 2.0+
- **Nginx**: 1.18+
- **Redis**: 6.0+
- **MySQL**: 8.0+ æˆ– PostgreSQL 13+

## ğŸ—ï¸ ç”Ÿäº§ç¯å¢ƒæ¶æ„

### æ¨èæ¶æ„

```
                    [è´Ÿè½½å‡è¡¡å™¨]
                         |
                    [Nginx åå‘ä»£ç†]
                         |
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        |                |                |
    [Web æœåŠ¡å™¨]    [Web æœåŠ¡å™¨]    [Web æœåŠ¡å™¨]
        |                |                |
    [åº”ç”¨å®¹å™¨]      [åº”ç”¨å®¹å™¨]      [åº”ç”¨å®¹å™¨]
        |                |                |
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    |             å…±äº«æœåŠ¡å±‚                    |
    |  [Redis]  [MySQL]  [PostgreSQL]        |
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å®¹å™¨åŒ–éƒ¨ç½²

```yaml
# docker-compose.production.yml
version: '3.8'

services:
  # åº”ç”¨æœåŠ¡
  app:
    build: .
    image: myplatform:latest
    container_name: myplatform_app
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - REDIS_HOST=redis
      - MYSQL_HOST=mysql
      - POSTGRES_HOST=postgres
    depends_on:
      - redis
      - mysql
      - postgres
    networks:
      - app_network
    volumes:
      - app_data:/app/data
      - app_logs:/app/logs

  # Redis æœåŠ¡
  redis:
    image: redis:7-alpine
    container_name: myplatform_redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    networks:
      - app_network

  # MySQL æœåŠ¡
  mysql:
    image: mysql:8.0
    container_name: myplatform_mysql
    restart: unless-stopped
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
    volumes:
      - mysql_data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app_network

  # PostgreSQL æœåŠ¡
  postgres:
    image: postgres:15-alpine
    container_name: myplatform_postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app_network

  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: myplatform_nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - app_logs:/var/log/nginx
    depends_on:
      - app
    networks:
      - app_network

volumes:
  app_data:
  app_logs:
  redis_data:
  mysql_data:
  postgres_data:

networks:
  app_network:
    driver: bridge
```

## ğŸ”§ ç”Ÿäº§ç¯å¢ƒé…ç½®

### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env.production
# åº”ç”¨é…ç½®
NODE_ENV=production
DEBUG=false
LOG_LEVEL=INFO

# æ•°æ®åº“é…ç½®
MYSQL_HOST=mysql
MYSQL_PORT=3306
MYSQL_DATABASE=myplatform_prod
MYSQL_USERNAME=myplatform_user
MYSQL_PASSWORD=strong_password_here
MYSQL_ROOT_PASSWORD=very_strong_root_password

POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DATABASE=myplatform_prod
POSTGRES_USERNAME=myplatform_user
POSTGRES_PASSWORD=strong_password_here

# Redis é…ç½®
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=strong_redis_password
REDIS_DB=0

# å®‰å…¨é…ç½®
SECRET_KEY=your_super_secret_key_here
JWT_SECRET=your_jwt_secret_here
ENCRYPTION_KEY=your_encryption_key_here

# å¤–éƒ¨æœåŠ¡é…ç½®
API_RATE_LIMIT=1000
SESSION_TIMEOUT=3600
```

### Nginx é…ç½®

```nginx
# nginx.conf
events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;

    # åŸºæœ¬è®¾ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzip å‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # ä¸Šæ¸¸æœåŠ¡å™¨
    upstream app_servers {
        server app:8000;
        # å¯ä»¥æ·»åŠ æ›´å¤šåº”ç”¨æœåŠ¡å™¨
        # server app2:8000;
        # server app3:8000;
    }

    # HTTP æœåŠ¡å™¨
    server {
        listen 80;
        server_name your-domain.com;
        
        # é‡å®šå‘åˆ° HTTPS
        return 301 https://$server_name$request_uri;
    }

    # HTTPS æœåŠ¡å™¨
    server {
        listen 443 ssl http2;
        server_name your-domain.com;

        # SSL è¯ä¹¦
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;

        # å®‰å…¨å¤´
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        add_header X-Frame-Options DENY always;
        add_header X-Content-Type-Options nosniff always;
        add_header X-XSS-Protection "1; mode=block" always;

        # å®¢æˆ·ç«¯æœ€å¤§è¯·æ±‚å¤§å°
        client_max_body_size 100M;

        # ä»£ç†è®¾ç½®
        location / {
            proxy_pass http://app_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # è¶…æ—¶è®¾ç½®
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }

        # é™æ€æ–‡ä»¶
        location /static/ {
            alias /app/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

### åº”ç”¨é…ç½®

```python
# config/production.py
from common.config.settings import BaseSettings

class ProductionSettings(BaseSettings):
    """ç”Ÿäº§ç¯å¢ƒé…ç½®"""
    
    # ç¯å¢ƒæ ‡è¯†
    ENV: str = "production"
    DEBUG: bool = False
    
    # æ—¥å¿—é…ç½®
    LOG_LEVEL: str = "INFO"
    LOG_FILE: str = "/app/logs/app.log"
    LOG_MAX_SIZE: str = "100MB"
    LOG_BACKUP_COUNT: int = 5
    
    # å®‰å…¨é…ç½®
    SECRET_KEY: str
    JWT_SECRET: str
    ENCRYPTION_KEY: str
    
    # æ•°æ®åº“é…ç½®
    MYSQL_HOST: str = "mysql"
    MYSQL_PORT: int = 3306
    MYSQL_DATABASE: str
    MYSQL_USERNAME: str
    MYSQL_PASSWORD: str
    
    POSTGRES_HOST: str = "postgres"
    POSTGRES_PORT: int = 5432
    POSTGRES_DATABASE: str
    POSTGRES_USERNAME: str
    POSTGRES_PASSWORD: str
    
    # Redis é…ç½®
    REDIS_HOST: str = "redis"
    REDIS_PORT: int = 6379
    REDIS_PASSWORD: str
    REDIS_DB: int = 0
    
    # æ€§èƒ½é…ç½®
    WORKER_PROCESSES: int = 4
    WORKER_THREADS: int = 2
    MAX_REQUESTS: int = 1000
    MAX_REQUESTS_JITTER: int = 100
    
    # ç›‘æ§é…ç½®
    ENABLE_METRICS: bool = True
    METRICS_PORT: int = 9090
    HEALTH_CHECK_INTERVAL: int = 30
    
    class Config:
        env_file = ".env.production"
```

## ğŸš€ éƒ¨ç½²æµç¨‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# å®‰è£…å¿…è¦è½¯ä»¶
sudo apt install -y curl wget git unzip

# å®‰è£… Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# å®‰è£… Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# åˆ›å»ºåº”ç”¨ç›®å½•
sudo mkdir -p /opt/myplatform
sudo chown $USER:$USER /opt/myplatform
cd /opt/myplatform
```

### 2. ä»£ç éƒ¨ç½²

```bash
# å…‹éš†ä»£ç 
git clone https://github.com/your-username/myplatform.git .

# åˆ‡æ¢åˆ°ç”Ÿäº§åˆ†æ”¯
git checkout production

# åˆ›å»ºç”Ÿäº§ç¯å¢ƒé…ç½®
cp .env.example .env.production
# ç¼–è¾‘ .env.production æ–‡ä»¶

# åˆ›å»º SSL è¯ä¹¦ç›®å½•
mkdir -p ssl
# å°† SSL è¯ä¹¦æ–‡ä»¶æ”¾å…¥ ssl ç›®å½•
```

### 3. æ„å»ºå’Œå¯åŠ¨

```bash
# æ„å»ºé•œåƒ
docker-compose -f docker-compose.production.yml build

# å¯åŠ¨æœåŠ¡
docker-compose -f docker-compose.production.yml up -d

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose -f docker-compose.production.yml ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose -f docker-compose.production.yml logs -f
```

### 4. æ•°æ®åº“åˆå§‹åŒ–

```bash
# ç­‰å¾…æ•°æ®åº“æœåŠ¡å¯åŠ¨
sleep 30

# è¿è¡Œæ•°æ®åº“è¿ç§»
docker-compose -f docker-compose.production.yml exec app python manage.py migrate

# åˆ›å»ºè¶…çº§ç”¨æˆ·
docker-compose -f docker-compose.production.yml exec app python manage.py createsuperuser

# åˆå§‹åŒ–åŸºç¡€æ•°æ®
docker-compose -f docker-compose.production.yml exec app python manage.py loaddata initial_data
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### åº”ç”¨ç›‘æ§

```python
# monitoring/app_monitor.py
import psutil
import time
from common.logging.logger import get_logger

logger = get_logger(__name__)

class AppMonitor:
    """åº”ç”¨ç›‘æ§å™¨"""
    
    def __init__(self):
        self.logger = logger
    
    def get_system_metrics(self):
        """è·å–ç³»ç»ŸæŒ‡æ ‡"""
        return {
            "cpu_percent": psutil.cpu_percent(interval=1),
            "memory_percent": psutil.virtual_memory().percent,
            "disk_percent": psutil.disk_usage('/').percent,
            "network_io": psutil.net_io_counters()._asdict()
        }
    
    def get_process_metrics(self):
        """è·å–è¿›ç¨‹æŒ‡æ ‡"""
        process = psutil.Process()
        return {
            "cpu_percent": process.cpu_percent(),
            "memory_percent": process.memory_percent(),
            "num_threads": process.num_threads(),
            "open_files": len(process.open_files()),
            "connections": len(process.connections())
        }
    
    def log_metrics(self):
        """è®°å½•ç›‘æ§æŒ‡æ ‡"""
        system_metrics = self.get_system_metrics()
        process_metrics = self.get_process_metrics()
        
        self.logger.info("System metrics", extra={
            "system": system_metrics,
            "process": process_metrics
        })
    
    def start_monitoring(self, interval=60):
        """å¼€å§‹ç›‘æ§"""
        while True:
            try:
                self.log_metrics()
                time.sleep(interval)
            except Exception as e:
                self.logger.error(f"Monitoring error: {e}")
                time.sleep(interval)
```

### æ—¥å¿—ç®¡ç†

```python
# logging/production_logger.py
import logging
import logging.handlers
import os
from datetime import datetime

def setup_production_logging():
    """è®¾ç½®ç”Ÿäº§ç¯å¢ƒæ—¥å¿—"""
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = "/app/logs"
    os.makedirs(log_dir, exist_ok=True)
    
    # åº”ç”¨æ—¥å¿—
    app_logger = logging.getLogger("app")
    app_logger.setLevel(logging.INFO)
    
    # æ–‡ä»¶å¤„ç†å™¨
    app_handler = logging.handlers.RotatingFileHandler(
        os.path.join(log_dir, "app.log"),
        maxBytes=100*1024*1024,  # 100MB
        backupCount=5
    )
    
    # æ ¼å¼åŒ–å™¨
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    app_handler.setFormatter(formatter)
    
    app_logger.addHandler(app_handler)
    
    # é”™è¯¯æ—¥å¿—
    error_logger = logging.getLogger("error")
    error_logger.setLevel(logging.ERROR)
    
    error_handler = logging.handlers.RotatingFileHandler(
        os.path.join(log_dir, "error.log"),
        maxBytes=100*1024*1024,
        backupCount=5
    )
    error_handler.setFormatter(formatter)
    
    error_logger.addHandler(error_handler)
    
    return app_logger, error_logger
```

### å¥åº·æ£€æŸ¥

```python
# health/health_check.py
import asyncio
import aiohttp
from common.storage.redis_client import RedisClient
from common.storage.db_client import DatabaseManager

class HealthChecker:
    """å¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.redis_client = RedisClient()
        self.db_manager = DatabaseManager()
    
    async def check_redis(self):
        """æ£€æŸ¥ Redis è¿æ¥"""
        try:
            await self.redis_client.ping()
            return {"status": "healthy", "service": "redis"}
        except Exception as e:
            return {"status": "unhealthy", "service": "redis", "error": str(e)}
    
    async def check_database(self):
        """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
        try:
            self.db_manager.ping()
            return {"status": "healthy", "service": "database"}
        except Exception as e:
            return {"status": "unhealthy", "service": "database", "error": str(e)}
    
    async def check_external_apis(self):
        """æ£€æŸ¥å¤–éƒ¨ API"""
        results = []
        
        # æ£€æŸ¥ç¤ºä¾‹ API
        apis = [
            "https://httpbin.org/status/200",
            "https://jsonplaceholder.typicode.com/posts/1"
        ]
        
        async with aiohttp.ClientSession() as session:
            for api in apis:
                try:
                    async with session.get(api, timeout=5) as response:
                        if response.status == 200:
                            results.append({
                                "status": "healthy",
                                "service": api,
                                "response_time": response.headers.get("X-Response-Time", "N/A")
                            })
                        else:
                            results.append({
                                "status": "unhealthy",
                                "service": api,
                                "error": f"HTTP {response.status}"
                            })
                except Exception as e:
                    results.append({
                        "status": "unhealthy",
                        "service": api,
                        "error": str(e)
                    })
        
        return results
    
    async def comprehensive_check(self):
        """ç»¼åˆå¥åº·æ£€æŸ¥"""
        redis_status = await self.check_redis()
        db_status = await self.check_database()
        api_status = await self.check_external_apis()
        
        overall_status = "healthy"
        if any(result["status"] == "unhealthy" for result in [redis_status, db_status] + api_status):
            overall_status = "unhealthy"
        
        return {
            "status": overall_status,
            "timestamp": datetime.now().isoformat(),
            "services": {
                "redis": redis_status,
                "database": db_status,
                "external_apis": api_status
            }
        }
```

## ğŸ”’ å®‰å…¨é…ç½®

### é˜²ç«å¢™é…ç½®

```bash
# å®‰è£… UFW
sudo apt install ufw

# è®¾ç½®é»˜è®¤ç­–ç•¥
sudo ufw default deny incoming
sudo ufw default allow outgoing

# å…è®¸ SSH
sudo ufw allow ssh

# å…è®¸ HTTP/HTTPS
sudo ufw allow 80
sudo ufw allow 443

# å…è®¸åº”ç”¨ç«¯å£
sudo ufw allow 8000

# å¯ç”¨é˜²ç«å¢™
sudo ufw enable

# æŸ¥çœ‹çŠ¶æ€
sudo ufw status
```

### SSL è¯ä¹¦é…ç½®

```bash
# ä½¿ç”¨ Let's Encrypt è·å–å…è´¹è¯ä¹¦
sudo apt install certbot python3-certbot-nginx

# è·å–è¯ä¹¦
sudo certbot --nginx -d your-domain.com

# è‡ªåŠ¨ç»­æœŸ
sudo crontab -e
# æ·»åŠ ä»¥ä¸‹è¡Œ
0 12 * * * /usr/bin/certbot renew --quiet
```

### å®‰å…¨å¤´é…ç½®

```nginx
# åœ¨ nginx.conf ä¸­æ·»åŠ å®‰å…¨å¤´
add_header X-Frame-Options "SAMEORIGIN" always;
add_header X-Content-Type-Options "nosniff" always;
add_header X-XSS-Protection "1; mode=block" always;
add_header Referrer-Policy "strict-origin-when-cross-origin" always;
add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline';" always;
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### åº”ç”¨ä¼˜åŒ–

```python
# å¼‚æ­¥å¤„ç†
import asyncio
from concurrent.futures import ThreadPoolExecutor

# çº¿ç¨‹æ± 
executor = ThreadPoolExecutor(max_workers=10)

async def process_data_async(data_list):
    """å¼‚æ­¥å¤„ç†æ•°æ®"""
    tasks = []
    for data in data_list:
        task = asyncio.create_task(process_single_item(data))
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    return results

def process_single_item(data):
    """å¤„ç†å•ä¸ªæ•°æ®é¡¹"""
    # å¤„ç†é€»è¾‘
    pass
```

### æ•°æ®åº“ä¼˜åŒ–

```sql
-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_created_at ON users(created_at);

-- åˆ†åŒºè¡¨
CREATE TABLE logs (
    id INT AUTO_INCREMENT,
    log_date DATE,
    message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (YEAR(log_date)) (
    PARTITION p2023 VALUES LESS THAN (2024),
    PARTITION p2024 VALUES LESS THAN (2025)
);
```

### ç¼“å­˜ä¼˜åŒ–

```python
# å¤šçº§ç¼“å­˜ç­–ç•¥
from common.storage.cache import CacheManager

cache_manager = CacheManager()

# å†…å­˜ç¼“å­˜ (å¿«é€Ÿè®¿é—®)
cache_manager.add_layer("memory", MemoryCache(max_size=1000, ttl=300))

# Redis ç¼“å­˜ (æŒä¹…åŒ–)
cache_manager.add_layer("redis", RedisCache(ttl=3600))

# æ•°æ®åº“ (æœ€ç»ˆå­˜å‚¨)
def get_data_with_cache(key):
    """å¸¦ç¼“å­˜çš„æ•°æ®è·å–"""
    # ç¬¬ä¸€çº§ï¼šå†…å­˜ç¼“å­˜
    data = cache_manager.get(key, layer="memory")
    if data:
        return data
    
    # ç¬¬äºŒçº§ï¼šRedis ç¼“å­˜
    data = cache_manager.get(key, layer="redis")
    if data:
        # åŒæ­¥åˆ°å†…å­˜ç¼“å­˜
        cache_manager.set(key, data, ttl=300, layer="memory")
        return data
    
    # ç¬¬ä¸‰çº§ï¼šæ•°æ®åº“
    data = get_data_from_database(key)
    if data:
        # åŒæ­¥åˆ°æ‰€æœ‰ç¼“å­˜å±‚
        cache_manager.set(key, data, ttl=3600, layer="redis")
        cache_manager.set(key, data, ttl=300, layer="memory")
    
    return data
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æœåŠ¡æ— æ³•å¯åŠ¨

```bash
# æ£€æŸ¥æ—¥å¿—
docker-compose -f docker-compose.production.yml logs app

# æ£€æŸ¥ç«¯å£å ç”¨
sudo netstat -tlnp | grep :8000

# æ£€æŸ¥é…ç½®æ–‡ä»¶
docker-compose -f docker-compose.production.yml config
```

#### 2. æ•°æ®åº“è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
docker-compose -f docker-compose.production.yml exec mysql mysql -u root -p -e "SHOW PROCESSLIST;"

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker-compose -f docker-compose.production.yml exec app ping mysql

# æ£€æŸ¥ç¯å¢ƒå˜é‡
docker-compose -f docker-compose.production.yml exec app env | grep MYSQL
```

#### 3. Redis è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥ Redis çŠ¶æ€
docker-compose -f docker-compose.production.yml exec redis redis-cli ping

# æ£€æŸ¥å¯†ç é…ç½®
docker-compose -f docker-compose.production.yml exec redis redis-cli -a your_password ping

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
docker-compose -f docker-compose.production.yml exec redis redis-cli info memory
```

### æ€§èƒ½é—®é¢˜è¯Šæ–­

```bash
# æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨
docker stats

# æŸ¥çœ‹ç³»ç»Ÿèµ„æºä½¿ç”¨
htop
iotop
nethogs

# æŸ¥çœ‹ç½‘ç»œè¿æ¥
ss -tuln
netstat -i
```

## ğŸ“š ä¸‹ä¸€æ­¥

- æŸ¥çœ‹ [Docker éƒ¨ç½²æŒ‡å—](docker.md)
- äº†è§£ [ç›‘æ§æŒ‡å—](monitoring.md)
- é˜…è¯» [å¿«é€Ÿå¼€å§‹](../getting-started/quickstart.md)

## ğŸ¤ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°éƒ¨ç½²é—®é¢˜ï¼š

1. æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—
2. æŸ¥çœ‹å®¹å™¨æ—¥å¿—
3. éªŒè¯é…ç½®æ–‡ä»¶
4. è”ç³»æŠ€æœ¯æ”¯æŒ
